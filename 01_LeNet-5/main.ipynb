{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet implementation in PyTorch üèãüèª\n",
    "\n",
    "1. Load MNIST dataset\n",
    "2. Create ConvNet (LeNet)\n",
    "3. Train model\n",
    "4. Evaluate model\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Load MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms = v2.Compose(\n",
    "    [\n",
    "        v2.PILToTensor(),\n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Create datasets for training & validation, download if necessary\n",
    "training_set = torchvision.datasets.MNIST(\n",
    "    \"./data\", train=True, transform=transforms, download=True\n",
    ")\n",
    "validation_set = torchvision.datasets.MNIST(\n",
    "    \"./data\", train=False, transform=transforms, download=True\n",
    ")\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size=4, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(\n",
    "    validation_set, batch_size=4, shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape=torch.Size([4, 1, 28, 28]); labels=tensor([9, 2, 7, 4])\n"
     ]
    }
   ],
   "source": [
    "data_iter = iter(training_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(f\"{images.shape=}; {labels=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we have a batch of 4 images and their labels are `5, 8, 3, 8`.\n",
    "\n",
    "### Let's visualize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(ncols=4)  # 1 row & 4 column\n",
    "\n",
    "for i in range(4):\n",
    "    ax[i].imshow(images[i].permute(1, 2, 0))\n",
    "    ax[i].set_title(f\"label = {labels[i]}\")\n",
    "    ax[i].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Now, let's recreate `LeNet-5` ConvNet architecture.\n",
    "\n",
    "![LeNet](../00_assets/LeNet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNetModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.fc1 = nn.Linear(256, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.conv1(x)\n",
    "        y = self.relu(y)\n",
    "        y = self.pool1(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.pool2(y)\n",
    "        y = y.view(y.shape[0], -1)\n",
    "        y = self.fc1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc2(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.fc3(y)\n",
    "        y = self.relu(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = LeNetModel().to(device)\n",
    "sgd = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m train_x \u001b[38;5;241m=\u001b[39m train_x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      9\u001b[0m train_label \u001b[38;5;241m=\u001b[39m train_label\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 11\u001b[0m \u001b[43msgd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m predict_y \u001b[38;5;241m=\u001b[39m model(train_x\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_fn(predict_y, train_label)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_compile.py:24\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dynamo\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dynamo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecursive\u001b[49m\u001b[43m)\u001b[49m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_dynamo/decorators.py:47\u001b[0m, in \u001b[0;36mdisable\u001b[0;34m(fn, recursive)\u001b[0m\n\u001b[1;32m     45\u001b[0m         fn \u001b[38;5;241m=\u001b[39m innermost_fn(fn)\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[0;32m---> 47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDisableContext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DisableContext()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/_dynamo/eval_frame.py:290\u001b[0m, in \u001b[0;36m_TorchDynamoContext.__call__\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(fn)\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 290\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    292\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:697\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgetsourcefile\u001b[39m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    694\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the filename that can be used to locate an object's source.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    Return None if no way can be identified to get the source.\u001b[39;00m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 697\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[43mgetfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    698\u001b[0m     all_bytecode_suffixes \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mDEBUG_BYTECODE_SUFFIXES[:]\n\u001b[1;32m    699\u001b[0m     all_bytecode_suffixes \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mmachinery\u001b[38;5;241m.\u001b[39mOPTIMIZED_BYTECODE_SUFFIXES[:]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/package/package_importer.py:696\u001b[0m, in \u001b[0;36m_patched_getfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _package_imported_modules:\n\u001b[1;32m    695\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _package_imported_modules[\u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m]\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n\u001b[0;32m--> 696\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_orig_getfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:669\u001b[0m, in \u001b[0;36mgetfile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismethod(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__func__\u001b[39m\n\u001b[0;32m--> 669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43misfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    670\u001b[0m     \u001b[38;5;28mobject\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__code__\u001b[39m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m istraceback(\u001b[38;5;28mobject\u001b[39m):\n",
      "File \u001b[0;32m/Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/inspect.py:170\u001b[0m, in \u001b[0;36misfunction\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21misfunction\u001b[39m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    160\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return true if the object is a user-defined function.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m    Function objects provide these attributes:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03m        __annotations__ dict of parameter annotations\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03m        __kwdefaults__  dict of keyword only parameters with defaults\"\"\"\u001b[39;00m\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunctionType\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "all_epoch = 50\n",
    "prev_acc = 0\n",
    "for current_epoch in range(all_epoch):\n",
    "    model.train()\n",
    "    print(f\"Epoch: {current_epoch+1}\")\n",
    "    total_training_loss = 0\n",
    "    for idx, (train_x, train_label) in enumerate(training_loader):\n",
    "        train_x = train_x.to(device)\n",
    "        train_label = train_label.to(device)\n",
    "        \n",
    "        sgd.zero_grad()\n",
    "        predict_y = model(train_x.float())\n",
    "        loss = loss_fn(predict_y, train_label)\n",
    "        total_training_loss += loss\n",
    "        loss.backward()\n",
    "        sgd.step()\n",
    "\n",
    "    avg_training_loss = total_training_loss/(len(training_loader)*4) # batch size=4\n",
    "    print(f\"    average training loss: => {avg_training_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct_predictions=980; incorrect_predictions=9020\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct_predictions = 0\n",
    "incorrect_predictions = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, (test_x, test_label) in enumerate(validation_loader):\n",
    "        test_x = test_x.to(device)\n",
    "        test_label = test_label.to(device)\n",
    "        predict_y = model(test_x)\n",
    "        predict_y = torch.argmax(predict_y, dim=1)\n",
    "\n",
    "        correct_predictions += torch.sum(predict_y == test_label).item()\n",
    "        incorrect_predictions += torch.sum(predict_y != test_label).item()\n",
    "\n",
    "print(f\"{correct_predictions=}; {incorrect_predictions=}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
